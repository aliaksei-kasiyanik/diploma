\documentclass[a4paper,14pt]{extreport}

\usepackage{bsustyle/style/bsumain}
\usepackage{bsustyle/style/bsudiplomatitle}
\usepackage{blindtext}
\subfaculty{Кафедра вычислительной математики}


\title{УСКОРЕНИЕ СХОДИМОСТИ ПРОЦЕССОВ УСТАНОВЛЕНИЯ. ПЕРЕОБУСЛАВЛИВАНИЕ И ПОДАВЛЕНИЕ КОМПОНЕНТ}
\author{Касияник Алексей Леонидович}
\mentor{Фалейчик Борис Викторович \\
        кандидат физ.-мат. наук, \\
        доцент кафедры выч. мат.}
\reviewer{Зав. кафедры вычислительной математики\\
          кандидат физико-математических наук, доцент\\
          Мандрик Павел Алексеевич }

\begin{document}
  \maketitle

  {
    \renewcommand{\contentsname}{Содержание}
    \tableofcontents
  }

  \chapter*{Введение}
  \addcontentsline{toc}{chapter}{Введение}
  Жесткие задачи исследуются примерно со второй половины 20 века. Однако и сейчас сформулировать точное определение жесткости проблематично. Наиболее прагматическая точка зрения вместе с тем была и исторически наиболее ранней (Кертисс и Хиршфельдер, 1952 год): \textit{жесткие уравнения — это уравнения, для которых определенные неявные методы дают лучший результат, обычно несравненно более хороший, чем явные методы.} При этом определенную роль играют собственные значения матрицы Якоби, но важны и такие параметры, как размерность системы, гладкость решения или интервал интегрирования. 
Более полным является определение данное Ламбертом: \textit{если численный метод с ограниченной областью абсолютной устойчивости, примененный к системе с произвольными начальными условиями вынужден использовать на некотором интервале интегрирования величину шага, которая чрезмерно мала по отношению к гладкости точного решения на этом интервале, тогда говорят, что система является жесткой на этом интервале}\cite{hairer}.


Как известно, наиболее трудоёмким этапом численного интегрирования жёсткой системы (не)линейных обыкновенных дифференциальных уравнений (ОДУ) размерности n неявным методом является решение на каждом шаге системы (не)линейных уравнений, размерность которой пропорциональна n. В таком случае использование методов ньютоновского типа практически невозможно, а традиционные методы типа простой итерации либо не сходятся, либо сходятся очень медленно. В данной работе рассматриваются способы ускорения методов, основанных на процессах установления, которые применимы в указаной выше ситуации.
В работе исследованы два эффективных способа ускорения сходимости решения в процессе решения методами установления: переобусловливание и подавление компонент. Переобусловливание является классическим способом уменьшения «спектрального числа обусловленности» матрицы решаемой задачи, которое существенным образом определяет свойства сходимости итерационного процесса. С помощью операции переобусловливания производится уменьшение числа обусловленности, что положительно влияет на скорость сходимости процесса.


Также было замечено, что компоненты ошибки, которые соответствуют малым собственным значениям, сходятся медленно. Поэтому предположительно подавление ошибки медленно сходящися компонент может дать существенную прибавку в скорости сходимости итерационного процесса. В результате исследования данного феномена был предложен прием ускорения итерационного процесса, который  по аналогу со схожими алгоритмами из известных источников именуется «подавлением компонент».
Исследованию описанных проблем, разработке вычислительного алгоритмов, которые бы основывались на идее установления и при этом превосходили в скорости известные алгоритмы и посвящается данная работа.
  \label{c:intro}


  \chapter{Жесткие задачи}
  \label{c:stiff_problems}
  Тема численного решения однородных дифференциальных уравнений не нова, и, возможно, несколько удивителен тот факт, что методы, разработанные еще в начале 20 века, до сих пор являются основой наиболее эффективных и распространенных подходов при решении ОДУ. За прошедшее время были достигнуты значительные продвижения в надежности и эффективности этих методов, и большинство существующих типичных научных задач могут быть решены достаточно легко и быстро. Тем не менее есть некоторый класс задач, с которыми классические методы справиться не могут. Такие задачи, называемые «жесткими», слишком важны, чтобы их игнорировать, и слишком трудны, чтобы их решить. Они слишком важны, чтобы их игнорировать, так как они возникают при решении важных физических задач. Они слишком затратные при решении, так как из-за присущей им большой размерности и сложности, классические методы становятся слабо применимы даже несмотря на многократное увеличение мощности современной вычислительной техники. Классические методы решения требуют так много шагов, что ошибки округления могут сделать полученное решение далеким от приемлемого[2]. В этом разделе мы и рассмотрим понятие «жесткости», а также те ключевые проблемы, которые возникают при их решении.

  \section{Явление жесткости}
  \label{s:stiffness}
  Задачи, называемые жесткими, весьма разнообразны, и дать математически строгое определение жесткости непросто. Поэтому в литературе можно встретить различные определения жесткости, отличающиеся степенью строгости. Сущность же явления жесткости состоит в том, что решение, которое необходимо вычислить, меняется медленно, однако в любой его окрестности существуют быстро затухающие возмущения. Характерное время затухания их называют пограничным слоем. Наличие таких возмущений затрудняет получение медленно меняющегося решения численным способом. При этом жесткими могут быть как скалярные дифференциальные уравнения, так и, что встречается особенно часто, системы обыкновенных дифференциальных уравнений.
  
  
\begin{Definition}Система обыкновенных дифференциальных уравнений вида
  \begin{equation}
  \label{stiff:eq}
    u'(t)=Au(t)
  \end{equation}
  с постоянной $(n \times n)$-матрицей $ A $ называется жесткой, если: 
  \begin{enumerate}
  \item $Re\lambda _k <0, k=\overbar{1,n}$ (т.е. задача устойчива);
  \item Отношение $S = \dfrac{\max\limits_{1\leq k\leq n} |Re\lambda _k|}{\min\limits_{1\leq k\leq n} |Re\lambda _k|} $ велико (например, $S > 10$);
  \item Промежуток интегрирования велик по сравнению с длиной погранслоя.[Repn]
  \end{enumerate}
\end{Definition}

Число $S$ иногда называют \textit{коэффициентом жесткости} системы. 


Поскольку система нелинейных обыкновенных дифференциальных уравнений вида $u'(t)=f(t, u(t))$ может быть в окрестности некоторого известного решения $v(t)$ заменена линейной системой 
$$u'(t) = f_u (t, v + \theta (u-v))u + b(t), $$
где $f_u$ - матрица Якоби, а $b(t) = f(t, v)-f_u(t,v + \theta (u-v))v$, то понятие жесткости для нелинейных систем может быть определено аналогично. Заметим, однако, что за пределами класса систем линейных обыкновенных дифференциальных уравнений с постоянной матрицей полагаться на спектр как на источник надежной информации о распространении погрешности уже нельзя[Dekker, Verver].

  
  \section{Трудности, возникающие при численном решении}
  \label{s:stiff_troubles} Трудность численного решения жестких систем обыкновенных дифференциальных уравнений выражается в нескольких аспектах. При использовании традиционных явных пошаговых методов, основы которых были заложены более века назад, возникают сильные ограничения на длину шага интегрирования.
  
  
  Рассмотрим в качестве примера систему из двух независимых уравнений   
  \begin{equation}
  \label{stiff:system}
  \begin{cases}
   u_1'(t)=-\lambda_1 u_1(t), 
   \\
    u_2'(t)=-\lambda_2 u_2(t), t>0, \lambda_2 \gg \lambda_1 > 0.
  \end{cases}
  \end{equation}
  Эта система имеет решение $u(t)=(u_1(t), u_2(t))^T = (u_1^0 e^{-\lambda_1 t}, u_2^0 e^{-\lambda_2 t})^T$. При выписанных условия на $\lambda_1$ и $\lambda_2$, очевидно, компонента $u_2(t)$ решения затухает гораздо быстрее, чем $u_1(t)$ и, начиная с некоторого момента $t$ поведение вектора $u(t)$ почти полностью определяется компонентой $u_1(t)$. Однако при решении системы \eqref{stiff:system} численным методом величина шага интегрирования, как правило, определяется компонентой $u_2(t)$, не существенной с точки зрения поведения решения системы. Например, используя явный метод Эйлера, мы из первого уравнения имеем ограничения на шаг $\tau \le 2/\lambda_1$, а из второго - $\tau \le 2/\lambda_2$ и, таким образом, ясно, что для решения системы \eqref{stiff:system} как цельного математического объекта шаг $\tau$ ограничен величиной $2/\lambda_2$. Такая же ситуация типична и при решении любой системы обыкновенных дифференциальных уравнений вида \eqref{stiff:eq}.
  
Учитывая выше сказанное, можно сделать вывод, что для решения жестких задач наиболее пригодны те численные методы, которые требуют наиболее слабых ограничений на величину шага численного интегрирования из соображений устойчивости. Таким образом, традиционные явные пошаговые методы, основы которых были заложены более века назад, мало пригодны из-за сильных ограничений на длину шага интегрирования, обусловленных неудовлетворительными свойствами устойчивости таких методов. 

 
 Начиная с пятидесятых годов двадцатого столетия, для интегрирования жестких задач стали применяться неявные одно- и многошаговые методы, обладающие хорошими свойствами устойчивости. Они позволяют находить приближенное решение жестких задач на достаточно больших шагах. Наиболее эффективными на данный момент считаются неявные коллокационные методы типа Рунге–Кутты. Однако и эти методы обладают существенным недостатком, который состоит в необходимости решения на каждом шаге системы нелинейных уравнений, размерность которой пропорциональна размерности дифференциального уравнения и количеству стадий метода. Поэтому машинная реализация таких методов является весьма громоздкой, и, кроме того, возникающие системы нелинейных уравнений в общем случае могут быть неразрешимы. Применение неявных методов также затрудняется необходимостью вычисления матрицы Якоби.
 
 
 Стоит затронуть еще один важный момент, не относящийся напрямую к проблеме жесткости. Это вопрос о контроле точности приближенного решения. При пошаговом интегрировании
для этих целей обычно используется техника «откатов»: если вычисленная (по правилу Рунге,
например) оценка погрешности недостаточно мала, полученное приближение отбрасывается и
вычисления повторяются заново с уже меньшей длиной шага. Такой подход, во-первых, не экономичен, так как полностью игнорируется полученное на данном шаге приближенное решение,
которое может быть достаточно близким к точному. Вместо того, чтобы уменьшать шаг и повторять такие же вычисления, можно попытаться каким-то образом уточнить уже имеющееся
приближение. Во-вторых, несколько «откатов» подряд могут привести к недопустимо малым
значениям шага[Faleichik].

В настоящее время наиболее часто для этих целей используют либо неявные методы, либо методы, специально сконструированные для решения задач конкретного вида[Repnikov]. Хорошо применимыми при решении жестких систем являются методы, основанные на процессах установления, которые и рассматриваются в главе~\ref{c:stead_methods}. 



  
  \section{Примеры жестких задач}
  \label{s:stiff_examples}   
  

  \chapter{Методы установления}
  \label{c:stead_methods}
  В настоящей главе приводятся основные сведения о вычислительном алгоритме, основанном на идее установления. Рассмотриваются случаи применения как к линейной системе, так и к нелинейной системе обыкновенных дифференциальных уравнений. Линейный случай является исследуемым в численном эксперименте в главе~\ref{c:numer_ex}.
  
  \section{Линейная задача}
  \label{s:linear_problem}
Рассмотрим задачу Коши для неоднородной линейной системы обыкновенных дифференциальных уравнений (ОДУ):
	\begin{equation}
	\begin{aligned}
	\label{main_problem}
	&y'(t)=Jy(t)+f(t),\\
	&y(t_0)=y_0,\\
	&t \in [t_0, t_0+\tau],\quad \\
	&y_0\in \mathbb{R}^N,\quad
	y:[t_0,t_0+\tau] \to \mathbb{R}^N,\quad\\
	&J \in \mathbb{R}^N \times \mathbb{R}^N, \quad
	\tau \in [0, +\infty).\\
	\end{aligned}
	\end{equation} 
Для нахождения приближения к $y(t_0 + \tau), \tau > 0$ проинтегрируем её произвольным s-стадийным неявным методом типа Рунге-Кутты. Далее этот метод будем называть \textit{базовым методом}. Базовый метод может быть представлен следующей таблицей Бутчера:
	\begin{center}
	\begin{equation}
	\label{base_method}
	\begin{array}{l|lll}
	c_1& a_{11}& ...& a_{1s}\\
	...& ...& ...& ...\\
	c_s& a_{s1}& ...& a_{ss}\\
	\hline
	& b_1& ...& b_s\\
	\end{array}
	\end{equation}
	\end{center}
Здесь $A=(a_{i,j})_{i,j=1}^s$ - так называемая матрица Бутчера
базового метода. Тогда
	$$ y(t_0+\tau)\thickapprox y_1=y_0+\tau\sum_{i=1}^sb_ik_i,$$
где $\{k_i\}_{i=1}^s$ находятся как решение следующей системы линейных алгебраических уравнений (СЛАУ)
	$$k_i = J(y_0+\tau\sum_{j=1}^sa_{ij}k_j)+f(t_0+c_i\tau).$$
В дальнейшем будем пользоваться матричной записью этой СЛАУ:
	\begin{equation}\label{system_for_solving}
	\begin{aligned}
	&(\tau A\otimes J-I)k+g=0,\\
	&g=(g_1,g_2,..,g_s)^T, \quad g_i=f(t_0+c_i \tau)+Jy_0, \quad i=1,..,s,\\
	&k=(k_1,k_2,..,k_s)^T, \quad k_i \in \mathbb{R}^N.\\
	\end{aligned}
	\end{equation}
Здесь $\otimes$ обозначает кронекеровское произведение матриц[], по
определению которого получаем, что $$G=\tau A\otimes J-I$$ - блочная
матрица вида
	\begin{equation}
	\left(
	\begin{array}{llll}
	-1+\tau a_{11}J& \tau a_{12}J&...&\tau a_{1s}J\\
 	\tau a_{12}J&-1+\tau a_{22}J&...&\tau a_{2s}J\\
	...&...&...&...\\
	\tau a_{s1}J& \tau a_{s2}J&...&-1+\tau a_{ss}J\\
	\end{array}
	\right ).
	\end{equation}
Рассмотрим вспомогательное уравнение
	\begin{equation}
	\label{estEquation}
	k'=(\tau A\otimes J-I)k+g=Gk+g = r(k),
	\end{equation}
которое в дальнейшем будем называть уравнением установления.

Очевидно, что точное решение уравнения \eqref{system_for_solving} $k^*$ будет являться стационарным решением \eqref{estEquation}. Для этого достаточно, чтобы спектр матрицы $G$ целиком содержался в левой комплексной полуплоскости. Поэтому, если проинтегрировать~\eqref{estEquation}  каким-нибудь численным методом, то можно получить приближение к решению \eqref{system_for_solving}.

Для решения \eqref{estEquation} будем использовать явный метод Рунге-Кутты, задаваемый таблицей вида
	\begin{equation}
	\label{auxilary_method_table}
	\begin{array}{lllll}
	 \alpha_{21}& & & &  \\
	 \alpha_{31}&\alpha_{32} & & &  \\
	 ...& ...& ...& &\\
	 \alpha_{\sigma1}& \alpha_{\sigma2}&... &\alpha_{\sigma\sigma-1}&  \\
	\hline
	 \beta_1&\beta_2 &...&\beta_{\sigma-1}& \beta_\sigma\\
	\end{array}
	\end{equation}
Пусть $\omega$ - шаг по фиктивному времени. В результате получаем итерационный процесс вида
	\begin{equation}\label{ipe_gf}
	\begin{aligned}
	&k^{l+1}=\Phi(k^{l})\\
	&\Phi(k)=k+\omega \sum_{p=1}^\sigma\beta_pK_p(k),\\
	&K_p(k)=G (k +\omega\sum_{q=1}^{p-1}\alpha_{pq} K_q(k))+g.
	\end{aligned}
	\end{equation}
Учитывая специфику интегрирования уравнения установления \eqref{estEquation}, нужно выбрать  $\omega$, $\{\alpha_{ij}\}_{i,j=1}^{\sigma}$, $\{\beta_i\}_{i=1}^{\sigma}$. Подробно выбор коэффициентов вспомогательного метода описан в [Bondar].
  
  \section{Нелинейная задача}
  \label{s:non_linear_problem} 
  
Рассуждения для нелинейного случая проходят во многом аналогично случаю линейному, поэтому остановимся только на различиях.

Рассмотрим систему нелинейных дифференциальных уравнений
	\begin{equation}
	\begin{aligned}
	\label{nolin_main_problem}
	&y'(t)=f(t, y(t)),\\
	&y(t_0)=y_0,\\
	&t \in [t_0, t_0+\tau],\quad \tau>0 \\
	&y_0\in \mathbb{R}^N,\quad
	y:[t_0,t_0+\tau] \to \mathbb{R}^N,\quad\\
	&f:  \mathbb{R}^N \to \mathbb{R}^N.
	\end{aligned}
	\end{equation}
Для интегрирования воспользуемся методом \eqref{base_method}, причем в отличие от линейного случая применение запишем в симметричном виде:
	$$Y_i = y_0+\tau \sum_{j = 1}^s a_{i,j}f(t_0+c_j \tau,Y_j), $$
	$$y(t_0+\tau)\thickapprox y_1 = y_0 + \tau \sum_{j = 1}^s b_{j}f(t_0+c_i \tau,Y_j),$$
что в векторной форме представимо как
	\begin{equation}
	\begin{aligned}
	\label{nolin_system_for_solving1}
	&Y = e\otimes y_0 +\tau (A\otimes I)F(t_0,Y),\\
	&y_1 = e\otimes y_0 +\tau(b^T\otimes I)F(t_0,Y).
	\end{aligned}
	\end{equation}
Здесь $e = (1,..., 1)$, $e \in \mathbb R^s$,  $Y = (Y_1, ...,Y_s)^T$, $F(t, Y) =\\= \left(f(t+c_1 \tau,Y_1),..., f(t+c_s \tau,Y_s) \right)^T$.
Уравнение установления для \eqref{nolin_system_for_solving1} имеет вид
	\begin{equation}
	\label{nolin_estEquation} Y(\theta)'=\tau (A\otimes I)F(t_0,Y(\theta)) -Y(\theta)+ e\otimes y_0 = \tilde r(Y(\theta)).
	\end{equation}
Соответствующий ему процесс установления имеет вид аналогичный \eqref{ipe_gf}:
	\begin{equation}
	\label{nolin_ipe_gf}
	\begin{aligned}
	&Y^{l+1}=\Phi(Y^{l}),\\
	&\Phi(Y)=Y+\omega \sum_{p=1}^{\sigma}\beta_{p}K_p(Y),\\
	&K_p(Y)=\tilde r(t_0,Y+\omega \sum_{q=1}^{p-1}\alpha_{pq}K_q(Y)).
	\end{aligned}
	\end{equation}
Полностью повторить конструирование вспомогательного метода как в случае
линейной системы вообще говоря нельзя. Однако если задача позволяет, то можно
провести линеаризацию и исследовать спектральные свойства уже для неё, полностью
повторяя приведенные в [Bondar] рассуждения о конструировании вспомогательных методов.
Параметр $\omega$ полагаем таким, чтобы все собственные значения матрицы Якоби
правой части уравнения \eqref{nolin_estEquation} были по модулю меньше 1.
  
  \section{Спектральные свойства и скорость сходимости итерационного процесса}
  \label{s:spectral_speed} 
Процесс \eqref{nolin_ipe_gf} представим в следующем виде:
	\begin{equation}
	\label{ipe_spektr_form}
	k^{l+1} = R_\sigma(\omega G)k^l+P(\omega, G),
	\end{equation}
где $R_\sigma$ - многочлен степени $\sigma$, называемый многочленом перехода (функцией устойчивости),  $P$ - функция, точный вид которой несущественен в данном случае.
	
	Известно, что многочлен перехода во многом определяет свойства устойчивости метода интегрирования ОДУ. В нашем же случае он определяет свойства сходимости итерационного процесса. Мы заинтересованы в том, чтобы вспомогательный метод был устойчив на как можно большей области. В частности, область устойчивости
$$ S = \{z \in \mathbb{C}\ :\  |R_{\sigma}(z)|<1  \}$$
должна содержать в себе  спектр матрицы $\omega G$[BondarFaleichikKiiv].

Положим $\omega$ равным спектральному радиусу матрицы $G$. Тем самым получаем, что в данном случае спектр матрицы $\omega G$ будет полностью содержаться в области устойчивости. Таким образом, спектр матрицы $\omega G$ имеет определяющее влияние на сходимость итерационного процесса \eqref{nolin_ipe_gf}.

Предположим, что нам известен спектр исходной матрицы $J$, и отследим каким может быть спектр результирующей матрицы
	$$G = \tau(A\otimes J) - I.$$
По свойству кронекеровскго произведения матриц [Dekker], собственные значения $\nu_{i,j}$ матрицы $G$ равны
	\begin{equation}\label{spektrG}
	\nu_{ij} = \tau \mu_j \lambda_i - 1,
	\end{equation}
где $\mu_i$ -- собственные значения матрицы $A$, $\lambda_j$ - собственные значения матрицы $J$. То есть, над  спектром исходной матрицы системы \eqref{main_problem} производятся операции масштабирования,поворота и параллельного переноса. Собственные значения матрицы $\omega G$, очевидно, являются смасштабированными на единичный круг собственными значениями  $G$. 

Описанные преобразования могут привести к выходу спектра матрицы $G$ за пределы левой комплексной полуплоскости, что по определению плохо – процессы установления становится неприменимыми. Но даже если выход не произошел, нет гарантии что такая ситуация не возникнет при увеличении шага интегрирования по
времени. Чтобы избежать описанного выше нежелательного явления, можно осуществить так называемую операцию переобусловливания. Применение операции переобусловливания к методам установления подробно рассматривается  в главе~\ref{s:precond}.

Проследим как будет изменяться ошибка на $l$-ой итерации:$\varepsilon^l= k^* - k^l$. Учитывая \eqref{ipe_spektr_form}, получим:
	$$\varepsilon^l = R_\sigma (\omega G)\varepsilon^{l-1}$$
Далее предположим, что у матрицы $G$ имеется полный набор собственных векторов $\{\eta^i\}_{i=1}^N$. Тогда

	$$ \varepsilon^l = \sum_{i = 1}^{N}\varepsilon_i^{l-1}R(\omega G) \eta^i = 		\sum_{i=1}^{N}\varepsilon_i^{l-1}R(\omega \nu_i )\eta^i,$$
здесь $\nu_i$ -- собственное значение, соответствующее $\eta^i$. Таким образом,% получили соотношение для ошибки на $l$-ой итерации:
	$$ \varepsilon_i^l = R_\sigma(\omega \nu_i) \varepsilon_i^{l-1} = (R(\omega \nu_i))^l\varepsilon_i^0.$$
Проанализируем последнее выражение. $R_\sigma$ -- многочлен перехода, и по построению $R_\sigma(0) = 1$. Учитывая непрерывность $R_\sigma$, получим что $R_\sigma$ близок к 1 когда $\omega \nu_i$ близко к 0. Это значит, что компоненты ошибки, соответствующие малым величинам $\omega \nu_i$, будут уменьшаться медленно. Нетрудно видеть, что характеристикой,  в достаточной мере описывающей свойства сходимости, является так называемое ``спектральное число обусловленности'' матрицы $J$ исходной системы, $\varkappa = \rho(J) \rho(J^{-1})$ ($\rho$ здесь - спектральный радиус). Чем больше эта величина, тем медленнее будет сходиться итерационный процесс.
  
  \chapter{Ускорение сходимости}
  \label{c:converg_accel}
  
  \section{Переобусловливание}
  \label{s:precond}
Переобусловливание - это процесс преобразования условий задачи для ее более корректного решения. Переобусловливание обычно связавно с уменьшением числа обучловленности задачи. Переобусловливаемая задача, как правило, затем решается итерационным методом. В линейной алгебре и вычислительной математике является переобусловливателем для матрицы  если у матрицы число обусловленности меньше, чем у Также чаще говорят, что  это переобусловливатель, чем просто так как точное значение обычно требует больших затрат на вычисление. Поэтому под переобуславливанием часто понимают вычисление  точнее произведение вектора-столбца или матрицы векторов-столбцов на  что обычно выполняется сложными программными пакетами с использованием итерационных методов, где в конечном итоге не вычисляются точные значения ни для , ни для .
    
  \subsection{Первый способ}
  \label{ss:precond_1}
  
  \subsection{Второй способ}
  \label{ss:precond_2}
  
  \section{Подавление компонент}
  \label{s:opress}
Пусть $x^0, x^1, \ldots, x^k$ -- вектора решений размерности $N$, полученные в ходе итераций процесса установления, а $\lambda_1 > \lambda_2 > \ldots > \lambda_n$ -- собственные значения.

Разложение ошибки по базису собственных векторов представимо в следующем виде: 
	\begin{itemize}
	  \item на $k$-ом шаге\hfill
	  	\begin{equation}\label{komp:nev1}
	  	 r^k=Ax^k - b=\sum_{i=1}^{N}\alpha_i^k\xi_i
	  	 \end{equation}
	  \item на $k+1$-ом шаге\hfill
	  	\begin{equation}\label{komp:nev2}
	  	r^{k+1}=\sum_{i=1}^{N}\alpha_i^kR(\omega\lambda_i)\xi_i
	  	\end{equation}
	\end{itemize}
	
Если $\lambda_i$ велико, то вклад соответствующей компоненты в ошибку будет невелик. Пусть $m$ -- номер собственного значения, соответствующего компоненте с наибольшим вкладом в ошибку, то есть $\lambda_m$ -- наименьшее по модулю собственное значение. Тогда
	\begin{equation}
	\label{komp:nev3}	
	\begin{aligned}
		r^k&=\alpha_k^m\xi_m + \varepsilon^k,\\
	    r^{k+1}&=\alpha_m^kR(\omega\lambda_m)\xi_m + \varepsilon^{k+1},
	 \end{aligned}
	\end{equation}
где $\epsilon^k$ -- погрешность, вносимая всеми компонентами помимо $m$-ой.

В предположении, что 
	\begin{equation}
	\label{komp:error1}	
	\begin{aligned}
		\alpha_k^m\xi_m &\gg \varepsilon^k,\\
	    \alpha_m^kR(\omega\lambda_m)\xi_m &\gg \varepsilon^{k+1},
	 \end{aligned}
	\end{equation}
получаем, что величина $\varepsilon^k$ значительно меньше вклада в погрешность $m$-ой компоненты. 

Следовательно,
	\begin{equation}
	\label{komp:nev_ratio}	
		\frac{r_k^j}{r_j^k} \approx R(\omega \lambda_m), j=\overbar{1, N}\\
	\end{equation}

Пусть $$\widetilde{x} \approx x^{k+1} + \delta^{k+1}$$.

Тогда 	
	\begin{equation}
	\label{komp:many_eq1}	
		\begin{aligned}
		A\widetilde{x} - b &= 0 \\
		A(x^{k+1} + \delta^{k+1}) - b &= 0 \\
		Ax^{k+1} + \delta^{k+1} - b &= 0 \\
		r^{k+1} + A\delta^{k+1} &= 0
		\end{aligned}
	\end{equation}

Следовательно, в предположении, что $\varepsilon^{k+1}$ мало, получаем
	\begin{equation}
	\label{komp:many_eq2}	
		\begin{aligned}
		\delta^{k+1} &= -A^{-1}r^{k+1} = -A^{-1}(\alpha_m^kR(\omega\lambda_m)\xi_m + \varepsilon^{k+1}) = \\ &= -\alpha_m^k R(\omega \lambda_m)A^{-1}\xi_m -A^{-1}\varepsilon{k+1} = \\ &= -\frac{1}{\lambda_m} \alpha_m^kR(\omega \lambda_m)\xi_m - A^{-1}\varepsilon^{k+1} = \\ &= -\frac{1}{\lambda_m} r^{k+1} - A^{-1}\varepsilon^{k+1} \approx -\frac{1}{\lambda_m}r^{k+1}
		\end{aligned}
	\end{equation}

Получим оценку для $\lambda_m$, для чего разложим многочлен перехода $R_\sigma(x)$ в ряд Тейлора:
	\begin{equation}
	\label{komp:taylor1}	
	R_\sigma(x) \approx R_\sigma(0) + R_\sigma'(0)x \approx 1 + xR_\sigma'(0)
	\end{equation}
Тогда,
	\begin{equation}
	\label{komp:taylor2}	
	R_\sigma(\omega\lambda_m) \approx 1 + R_\sigma'(0)\omega\lambda_m \approx \frac{r_j^{k+1}}{r_j^k}, j=\overbar{1, N}
	\end{equation}
Следовательно, приближенное значение собственного значения $\lambda_m$, соответствующего компоненте с наибольшим вкладом в ошибку, можно вычислить следующим образом:
\begin{equation}
	\label{komp:lambda}	
	\lambda_m \approx \frac{ {}^{r_j^{k+1}}/_{r_j^k} - 1}{\omega R_\sigma'(0)}, j=\overbar{1, N}
	\end{equation}
	
Таким образом, получаем возможность уточнить текущее приближение следующим способом:
	\begin{equation}	
	\label{komp:opressioneq}	
	\widetilde{x} \approx x^{k+1} + \dfrac{1}{\lambda_m}r^{k+1}.
	\end{equation}

При практической реализации, невзирая на то, что полученные оценки должны выполняться для любых допустимых $j$, рекомендуется для расчетов выбирать медианное значение ряда $\dfrac{r_1^{k+1}}{r_1^k}, \ldots, \dfrac{r_N^{k+1}}{r_N^k}$.

Также отметим, что определение, когда именно нужно производить уточнение решения, требует дополнительных исследований. При проведении численного эксперимента пробовалась различная частота применения операции продавления компонент, результаты чего описаны в главе~\ref{c:numer_ex}
  
  
  \chapter{Численный эксперимент}
  \label{c:numer_ex}
  
  \section{Тестовая задача}
  \label{s:test_problem}
  
  \section{Результаты численного эксперимента}
  \label{s:results}
  
  
\newpage

\begin{thebibliography}{99}

\bibitem{hairer}Хайрер Э., Ваннер Г.  Решение обыкновенных дифференциальных уравнений. Жесткие и дифференциально-алгебраические задачи./ Пер. с англ. — М.: Мир, 1999. — 685 с.

\bibitem{dekker}Деккер К., Вервер Я. Устойчивость методов Рунге—Кутты для жестких нелинейных дифференциальных уравнений/ Пер. с англ.— М.: Мир, 1988.

\bibitem{Faleichik_Bondar_Kyiv}Фалейчик Б. В., Бондарь И. В. Реализация неявных методов для жестких задач методом установления// Theoretical and Applied Aspects of Cybernetics. Proceedings of the International Scientific Conference of Students and Young Scientists -- Kyiv: Bukrek, 2011. С. 297-299.

\bibitem{Faleichik_article}Faleichik B. V. Explicit Implementation of Collocation Methods for Stiff Systems with Complex Spectrum // Journal of Numerical Analysis, Industrial and Applied Mathematics. Vol. 5

\bibitem{Faleichik_bondar_amade}Фалейчик Б. В., Бондарь И. В. Реализация неявных методов Рунге-Кутты с использованием принципа установления //Аналитические методы анализа и дифференциальных уравнений: Тез. докл. междунар. конф. 12-17 сент. 2011г, Минск, Беларусь. С. 146-147

\bibitem{Faleichik_amade}Фалейчик Б. В. Реализация неявных методов для жестких задач с использованием обобщенных итераций Пикара // Тр. 6-й международной конференции «Аналитические методы анализа и дифференциальных уравнений»: в двух томах – Т.1 Математический анализ. — Минск: Институт математики НАН Беларуси, 2012. С. 131–135.

\bibitem{gomel}Фалейчик Б. В., Бондарь И. В. Реализация неявных методов Рунге-Кутты для больших жестких систем//Новые математические методы и компьютерные технологии в проектировании, производстве и научных исследованиях: XV Республиканская научная конференция студентов и аспирантов ``Новые математические методы и компьютерные технологии в проектировании, производстве и научных исследованиях'', 26-28 марта 2012 г.:[материалы]: в 2 ч. Ч.1/редкол. : Демиденко О.М. -- Гомель: ГГУ им. Ф. Скорины, 2012. С. 175-176

\bibitem{konf_may}Бондарь И. В. Итерационные процессы установления для жестких линейных задач //Тр. 69-й ежегодной научной конференции студентов и аспирантов БГУ: допущено в печать.

\bibitem{deal} Интернет адрес: http://www.dealii.org
\end{thebibliography}


  \appendix
\end{document}
